{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d79d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import pickle, os\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#\n",
    "# Short script to organize particle abundances into a single data \n",
    "#  structure which consists of a list of dictionaries, keyed by a\n",
    "#  string representing the isotope. There is one list entry per\n",
    "#  particle. This data structure is subsequently read as a pickle \n",
    "#  from a file.\n",
    "#\n",
    "#  - rtf 092816\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "f = open ('plotdata', 'w')\n",
    "\n",
    "f.write (\"#CatoS 55Chain  56Chain  57Chain Ye\" + \"\\n\")\n",
    "\n",
    "for filename in sorted (os.listdir('.')):\n",
    "\n",
    "    if filename.startswith(\"decayed\"):\n",
    "#  if filename.endswith(\".0Z.p\") and filename.startswith(\"final\"): \n",
    "\n",
    "    print (\"Reading data from file...\", filename)\n",
    "\n",
    "    mean_abundance = {} # initialize dictionary\n",
    "    total_particles = 0 # initialize total_particles count to 0\n",
    "\n",
    "    abundancematrix = pickle.load( open( filename, \"rb\" ) )\n",
    "    proton = pickle.load (open ('proton.p', \"rb\") )\n",
    "    baryon = pickle.load (open ('baryon.p', \"rb\") )\n",
    "\n",
    "    print (\"File read in.\")\n",
    "\n",
    "# Set mean abundances by looping over particles and species \n",
    "    for abundance in abundancematrix:   # loop over particles\n",
    "        total_particles += 1\n",
    "        for key in abundance:     # loop over species\n",
    "            if key in mean_abundance:   # check to see if entry exists\n",
    "                mean_abundance [key] += abundance [key]\n",
    "            else:                       # if entry doesn't exist, default\n",
    "                mean_abundance [key] = abundance [key]\n",
    "\n",
    "        norm = 0.\n",
    "        y_e = 0.\n",
    "\n",
    "# Normalize abundances by looping over species\n",
    "    for key in mean_abundance: # loop over species \n",
    "        mean_abundance [key] = mean_abundance [key] / total_particles\n",
    "#      Z = proton [key]\n",
    "#      A = baryon [key]\n",
    "#      N = A - Z\n",
    "#      y_e = y_e + mean_abundance [key] * Z / A\n",
    "#      if (mean_abundance [key] > 1.e-4):\n",
    "#        print key, \" \", mean_abundance [key], \" \", Z, \" \", A \n",
    "#        print key, \" \", mean_abundance [key]\n",
    "      norm += mean_abundance [key]\n",
    "\n",
    "    f.write (filename + \"\\n\")\n",
    "\n",
    "#    for key in mean_abundance:\n",
    "    for key in sorted (mean_abundance, key = mean_abundance.get, reverse=True):\n",
    "      f.write (key + \" \" + str (mean_abundance [key]) + \"\\n\")\n",
    "\n",
    "    if (abs (norm - 1.) > 0.01):\n",
    "      print \"Warning: Abundances not normalized to within 1%.\"\n",
    "\n",
    "# Output ca48 abundance, 55 chain, 56 chain, 57 chain, y_e\n",
    "#    f.write (filename + \": \\n\")\n",
    "\n",
    "#    f.write (str (crtofe) + \" \" + str (catos) +  \\\n",
    "#       \" \" +  str (chain55) + \" \" + str (chain56) + \" \" + \\\n",
    "#        str (chain57) + \"\\n\" )\n",
    "\n",
    "f.close()    \n",
    "#for key in sorted (mean_abundance, key = mean_abundance.get, reverse=True):\n",
    "#   f.write (key + \" \" + str (mean_abundance [key]) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
